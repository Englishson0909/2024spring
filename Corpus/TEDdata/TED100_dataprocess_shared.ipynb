{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Englishson0909/2024spring/blob/main/Corpus/TEDdata/TED100_dataprocess_shared.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final data to process**\n",
        "\n",
        "+ [Finaldata TED100](https://github.com/MK316/Spring2024/blob/main/Corpus/TEDdata/TED100.csv)"
      ],
      "metadata": {
        "id": "EJMwHlbZtd8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [1] Data to read\n",
        "(Updated 0605)\n",
        "\n",
        "+ [raw data link](https://raw.githubusercontent.com/MK316/Spring2024/main/Corpus/TEDdata/TED100.csv)\n",
        "\n",
        "|TID|Title|Duration|Text|\n",
        "|--|--|--|--|\n",
        "|1|How to speak so that people want to listen\\nJULIAN TREASURE|6_12|Text|\n",
        "\n"
      ],
      "metadata": {
        "id": "rX9h9D6DtjHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "datalink = \"https://raw.githubusercontent.com/MK316/Spring2024/main/Corpus/TEDdata/TED100.csv\"\n",
        "data = pd.read_csv(datalink, encoding=\"utf-8\")\n",
        "data.tail()"
      ],
      "metadata": {
        "id": "sSCI-U8EtiqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy data, and rename it as 'df' for further processes\n",
        "\n",
        "df = data"
      ],
      "metadata": {
        "id": "iNJTzhoPE6wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [2] Cleaned data: adding a column 'Cleanedtext01'\n",
        "\n",
        "+ data = original data (leave this as it is)\n",
        "+ data to df\n",
        "+ df: a cleaned data column will be added\n",
        "  + Remove timestamp and parenthetical notes\n",
        "  + Text to combine as a txt file: for searching\n",
        "  + Optionally: Add columns to get occurrences of a specific word or string"
      ],
      "metadata": {
        "id": "5Ld-HeYEt264"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split titles and speaker info"
      ],
      "metadata": {
        "id": "pxPaeoqiEpBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Split the 'Title' column into 'Titleonly' and 'Speakername'\n",
        "df[['Titleonly', 'Speaker']] = df['Title'].str.split('\\n', expand=True)\n",
        "\n",
        "# Define the desired order of columns\n",
        "desired_order = ['TID', 'Titleonly', 'Speaker','Duration', 'Text']\n",
        "\n",
        "# Reassign the DataFrame with columns in the desired order\n",
        "df = df[desired_order]\n",
        "\n",
        "df = df.rename(columns={'Titleonly': 'Title'})\n",
        "# Display the DataFrame to verify the result\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "Vz8qR1pqEsiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove timestamps and parenthetical notes > Add cleanedtext to a column 'Cleanedtext01'"
      ],
      "metadata": {
        "id": "6cfLyCteImZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # Remove timestamps in the format \"00:00\"\n",
        "        text = re.sub(r'\\d{2}:\\d{2}', '', text)\n",
        "        # Remove text within parentheses\n",
        "        text = re.sub(r'\\(.*?\\)', '', text)\n",
        "        # Clean up extra spaces that might result from removals\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply the clean_text function to each element in the 'Text' column\n",
        "df['Cleanedtext01'] = df['Text'].apply(clean_text)\n",
        "\n",
        "# Display the DataFrame to verify the result\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "3hXxntMtt2FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare two texts: original ('Text') and cleaned ('Cleanedtext01')"
      ],
      "metadata": {
        "id": "S24TisGTJvPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the first item of 'Text' and 'Cleanedtext01'\n",
        "comp = input('Which one to compare: (1~100)')\n",
        "com=int(comp)\n",
        "cn = com -1\n",
        "\n",
        "original_text = df['Text'].iloc[cn][:1000]  # Access the first item in the 'Text' column\n",
        "cleaned_text = df['Cleanedtext01'].iloc[cn][:1000]  # Access the first item in the 'Cleanedtext01' column\n",
        "\n",
        "print(f\"Original Text {com}:\")\n",
        "print(\"=\"*50)\n",
        "print(original_text)\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nCleaned Text {com}:\")\n",
        "print(\"=\"*50)\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "id": "ufFPcszABRzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [3] Check whether the data cleaning is appropriately processed"
      ],
      "metadata": {
        "id": "TKwMLvBjuX-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Function to remove and report timestamps\n",
        "def remove_and_report_timestamps(text):\n",
        "    # Find all occurrences of the timestamp pattern\n",
        "    matches = re.findall(r'\\d{2}:\\d{2}', text)\n",
        "    # Remove the timestamp pattern\n",
        "    cleaned_text = re.sub(r'\\d{2}:\\d{2}', '', text)\n",
        "    return cleaned_text, matches\n",
        "\n",
        "# Get user input and validate the index\n",
        "tn = input(\"Type the index of a text to check (1~100): \")\n",
        "try:\n",
        "    tn = int(tn)\n",
        "    if tn < 1 or tn > len(df):\n",
        "        raise ValueError(\"Index out of range\")\n",
        "except ValueError as e:\n",
        "    print(f\"Invalid input: {e}\")\n",
        "else:\n",
        "    n = tn - 1\n",
        "\n",
        "    # Apply the function and capture the cleaned text and the matches for 'Text'\n",
        "    cleaned_text_original, timestamp_matches_original = remove_and_report_timestamps(df['Text'][n])\n",
        "\n",
        "    # Print the number of occurrences and list each occurrence for 'Text'\n",
        "    if timestamp_matches_original:\n",
        "        print(f\"Found {len(timestamp_matches_original)} occurrences of the timestamp pattern in original text:\")\n",
        "        for match in timestamp_matches_original:\n",
        "            print(match)  # No need for .strip() since we removed \\n from the pattern\n",
        "    else:\n",
        "        print(\"No timestamp pattern found in the original text.\")\n",
        "\n",
        "    # Apply the same function and capture the cleaned text and the matches for 'Cleanedtext01'\n",
        "    cleaned_text_cleaned, timestamp_matches_cleaned = remove_and_report_timestamps(df['Text'][n])\n",
        "\n",
        "    # Print the number of occurrences and list each occurrence for 'Cleanedtext01'\n",
        "    if timestamp_matches_cleaned:\n",
        "        print(f\"Found {len(timestamp_matches_cleaned)} occurrences of the timestamp pattern in cleaned text:\")\n",
        "        for match in timestamp_matches_cleaned:\n",
        "            print(match)\n",
        "    else:\n",
        "        print(\"No timestamp pattern found in the cleaned text.\")\n",
        "\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Additional print to show cleaned text\n",
        "    print(\"Text Original:\\n\", df['Text'][n][:1000])\n",
        "    print(\"=\"*50)\n",
        "    print(\"Text Cleaned:\\n\", cleaned_text_cleaned[:1000])\n"
      ],
      "metadata": {
        "id": "1b7_lZARuYHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 2. Check the second (parenthetical notes) for both 'Text' and 'Cleanedtext01'\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "def remove_and_report_timestamps(text):\n",
        "    # Find all occurrences of the timestamp pattern\n",
        "    matches = re.findall(r'\\(.*?\\)', text)\n",
        "    # Remove the timestamp pattern\n",
        "    cleaned_text = re.sub(r'\\(.*?\\)', '', text)\n",
        "    return cleaned_text, matches\n",
        "\n",
        "# Apply the function and capture the cleaned text and the matches for 'Text'\n",
        "ts = input(\"Which text to check (1~100): \")\n",
        "ts = int(ts)\n",
        "s = ts-1\n",
        "cleaned_text_original, timestamp_matches_original = remove_and_report_timestamps(df['Text'][s])\n",
        "\n",
        "# Print the number of occurrences and list each occurrence for 'Text'\n",
        "if timestamp_matches_original:\n",
        "    print(f\"Found {len(timestamp_matches_original)} occurrences of the timestamp pattern in original text:\")\n",
        "    for match in timestamp_matches_original:\n",
        "        print(match.strip())  # .strip() is used to remove any trailing newline for clean display\n",
        "else:\n",
        "    print(\"No timestamp pattern found in the original text.\")\n",
        "\n",
        "# Apply the same function and capture the cleaned text and the matches for 'Cleanedtext01'\n",
        "cleaned_text_cleaned, timestamp_matches_cleaned = remove_and_report_timestamps(df['Cleanedtext01'][s])\n",
        "\n",
        "# Print the number of occurrences and list each occurrence for 'Cleanedtext01'\n",
        "if timestamp_matches_cleaned:\n",
        "    print(f\"Found {len(timestamp_matches_cleaned)} occurrences of the timestamp pattern in cleaned text:\")\n",
        "    for match in timestamp_matches_cleaned:\n",
        "        print(match.strip())\n",
        "else:\n",
        "    print(\"No parenthetical pattern found in the cleaned text.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4ZYSbiLsuYHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [4] Length information (string length)"
      ],
      "metadata": {
        "id": "MzcEujRSOCXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Add string length information as new columns\n",
        "df['Text_length'] = df['Text'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
        "df['Cleaned_length'] = df['Cleanedtext01'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
        "\n",
        "# Rearrange the columns as specified\n",
        "desired_order = ['TID', 'Title', 'Speaker', 'Duration', 'Text_length', 'Cleaned_length', 'Text', 'Cleanedtext01']\n",
        "df = df[desired_order]\n",
        "\n",
        "# Display the DataFrame to verify the result\n",
        "df.tail()\n"
      ],
      "metadata": {
        "id": "3Q9hUV-UOF4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [5] Word count information: as a new column (only for the cleaned data)"
      ],
      "metadata": {
        "id": "qwyUrpJKRMV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to count words in a string\n",
        "def count_words(text):\n",
        "    if isinstance(text, str):\n",
        "        return len(text.split())\n",
        "    return 0\n",
        "\n",
        "# Apply the count_words function to each element in the 'Cleanedtext01' column\n",
        "df['Wordcount'] = df['Cleanedtext01'].apply(count_words)\n",
        "\n",
        "# Rearrange the columns as specified\n",
        "desired_order = ['TID', 'Title', 'Speaker', 'Duration', 'Wordcount', 'Text_length', 'Cleaned_length', 'Text', 'Cleanedtext01']\n",
        "df = df[desired_order]\n",
        "\n",
        "# Display the DataFrame to verify the result\n",
        "df.tail()\n"
      ],
      "metadata": {
        "id": "le3xL2MtRSZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [5] Text to combine for searching (to check) and save it as a text file (Cleanedtext01ALL.txt)"
      ],
      "metadata": {
        "id": "yKL9NlRnwQvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Text to combine (df['Cleanedtext01]) as a single string\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "import string\n",
        "\n",
        "# 8) Combine all items in the 'Text' column as a single string and remove punctuation\n",
        "combined_text = ''.join(df['Cleanedtext01'].astype(str))\n",
        "combined_text = combined_text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Saving the text (Cleanedtext01 combined)\n",
        "\n",
        "# 8) Save the text\n",
        "my_string = combined_text\n",
        "\n",
        "# Define the file name\n",
        "file_name = \"Cleanedtext01ALL.txt\"\n",
        "\n",
        "# Open the file in write mode and save the string\n",
        "with open(file_name, \"w\") as file:\n",
        "    file.write(my_string)\n",
        "\n",
        "print(f\"File '{file_name}' saved successfully!\")"
      ],
      "metadata": {
        "id": "ehy6FSAAxd0_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search (with a word)"
      ],
      "metadata": {
        "id": "_LLBx8s_QPJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Searching a match (complete or partial)\n",
        "\n",
        "# 3) Get user input for the word to find\n",
        "search_word = input(\"Enter the word to find: \")\n",
        "match_type = input(\"Type 'c' complete matches only, or 'p' for partial matches: \").lower()\n",
        "\n",
        "# 4) Function to find occurrences\n",
        "def find_occurrences(text, word, match_type):\n",
        "    occurrences = []\n",
        "    position = 0\n",
        "    while True:\n",
        "        if match_type == 'c':\n",
        "            # Find whole words only by using boundaries\n",
        "            position = text.lower().find(f' {word.lower()} ', position)\n",
        "        else:\n",
        "            position = text.lower().find(word.lower(), position)\n",
        "\n",
        "        if position == -1:  # No more occurrences found\n",
        "            break\n",
        "        # Calculate start and end positions for slicing\n",
        "        start = max(0, position - 30)\n",
        "        end = min(len(text), position + len(word) + 30)\n",
        "        occurrences.append(text[start:end])\n",
        "        position += len(word)  # Move past this occurrence\n",
        "\n",
        "    return occurrences\n",
        "\n",
        "occurrences = find_occurrences(combined_text, search_word, match_type)\n",
        "\n",
        "# 5) Decide how many occurrences to display\n",
        "print(f\"Total occurrences found: {len(occurrences)}\")\n",
        "print(\"=\"*50)\n",
        "if len(occurrences) > 10:\n",
        "    choice = input(\"More than 10 occurrences found. Type 'a' to display all or '10' to display only the first 10: \").lower()\n",
        "    print(\"=\"*50)\n",
        "    if choice == '10':\n",
        "        occurrences = occurrences[:10]\n",
        "\n",
        "# 6) Display occurrences\n",
        "for occurrence in occurrences:\n",
        "    print(occurrence)\n",
        "\n",
        "# 7) Print summary\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GDpQeidDQPq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the processed file"
      ],
      "metadata": {
        "id": "sZJOJ_wH7Xm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "df.to_csv(\"Cleanedtext01.csv\", encoding = \"utf-8\", index=False)"
      ],
      "metadata": {
        "id": "9KqbYw4Y7cMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "The end"
      ],
      "metadata": {
        "id": "HY9m5h69R8_P"
      }
    }
  ]
}